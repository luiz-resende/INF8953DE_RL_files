{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62S_pk1osyRN"
      },
      "source": [
        "# **INF8953DE Reinforcement Learning (Fall 2021)**\n",
        "\n",
        "## **Final Project – Analysis of Deep Q-Network for Playing Atari**\n",
        "\n",
        "### **Authors:** Resende Silva, Luiz$^{1}$ & Talotsing, Gaëlle P. M.$^{2}$\n",
        "\n",
        "\\\n",
        "$1$ - luiz.resende-silva@polymtl.ca\n",
        "$2$ - gaelle-patricia-megouo.talotsing@polymtl.ca"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7fQzHLIs9gW"
      },
      "source": [
        "## **Python modules, classes and functions**\n",
        "\n",
        "### _MUST RUN_\n",
        "\n",
        "The cells below install the necessary Python modules and download and import environment ROMs and experiment scripts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-dryvkoNa30"
      },
      "source": [
        "### *Installing Python modules*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhUSQOo6h8nj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2c6839-115e-4dd9-9e9a-f429e4bea569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade pip\n",
        "!python -m pip install torch==1.10.0+cu111 torchaudio==0.10.0+cu111 torchvision==0.11.1+cu111\n",
        "!python -m pip install albumentations==1.1.0 ale-py==0.7.3 cmake==3.12.0 datascience==0.17.0 folium==0.12.1.post1 gym==0.21.0 imageio-ffmpeg==0.4.5 matplotlib==3.2.2 numpy==1.19.5 pandas==1.1.5 pyglet==1.5.21 pyvirtualdisplay==2.2 opencv-python==4.5.4.60  pygame==2.1.0 wandb==0.12.7 yellowbrick==1.3.post1\n",
        "!sudo apt-get install xvfb  # COMMENT-OUT IF RUNNING ON WINDOWS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx5DgyW-NlZH"
      },
      "source": [
        "### *Weights & Biases*\n",
        "\n",
        "The experiments set up uses [Weights & Biases](https://wandb.ai/site) to log training information. The ``wandb`` module allows for code automation, real-time visualization of the training process and general code cleanness.\n",
        "\n",
        "To use Weights & Biases, the user must create an account, go to the Weights & Biases account settings, retrieve the personal API key and replace ``<key>`` with the personal API key number (40-character combination). However, if the user does not want to use the ``wandb`` module, skip this cell and ensure that ``'use_wandb_logging': True`` inside the dictionary ``config_training``. The object of class ``AgentDQN`` will still have the arguments ``episodes_scores`` and ``episodes_losses`` that can be used as training quality metrics.\n",
        "\n",
        "**NOTE FOR WINDOWS**: remove the \"!\" if running on Windows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I29D_ZQQCzsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de5887f5-6b6b-4074-f80d-c8a5f7f95ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
          ]
        }
      ],
      "source": [
        "# LOGIN TO WEIGHTS & BIASES LOGGING MODULE\n",
        "!wandb login '<key>'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz5pXpPXORIC"
      },
      "source": [
        "### *Atari Environment ROMS*\n",
        "\n",
        "Downloading and installing the Atari ROMS for the [Arcade Learning Environment (ALE)](https://github.com/mgbellemare/Arcade-Learning-Environment), as well as the [MinAtar](https://github.com/kenjyoung/MinAtar) testbed and the modified ``env/registration.py`` script for [OpenAI Gym](https://gym.openai.com/docs/) (allows creating MinAtar-Gym environment).\n",
        "\n",
        "**NOTE FOR WINDOWS**: running this Python notebook on Windows, the commands ``!wget`` and ``!unzip`` will not be supported. The user should download and extract files in the below links and change the directory paths to import the Atari ROMS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XGNy9Tol0yn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4086a308-257b-4e8c-b0c7-e9486efe6a15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ]
        }
      ],
      "source": [
        "# RETRIEVING ATARI ROMS, MINATAR MODULE AND GYM ENVIRONMENT REGISTRATION ALLOWING MINATAR\n",
        "!wget https://github.com/luiz-resende/ReinforcementLearning/raw/main/A03_DQN/ROMS.zip\n",
        "!wget https://github.com/luiz-resende/ReinforcementLearning/raw/main/A03_DQN/MinAtar_gym.zip\n",
        "!wget https://github.com/luiz-resende/ReinforcementLearning/raw/main/A03_DQN/MinAtarModule.zip\n",
        "!unzip './ROMS.zip'\n",
        "!unzip './MinAtarModule.zip'\n",
        "!ale-import-roms './ROMS'\n",
        "\n",
        "!python -m pip install ./MinAtar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vEURfE6DG2w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "\n",
        "zipfile.ZipFile('MinAtar_gym.zip', 'r').extractall((os.path.abspath(np.__file__)[:-17] + 'gym/envs/'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Fe2XHN4QTDh"
      },
      "source": [
        "### *Agent, Model, Memory Buffer and Environment Wrapper scripts*\n",
        "\n",
        "[Luiz Resende Silva](mailto:luiz.resende-silva@polymtl.ca) implemented the scripts for the different classes used in the experiment, keeping them in his [GitHub page](https://github.com/luiz-resende/ReinforcementLearning/tree/main/A03_DQN) to maintain a clean and small-sized ``.ipynb`` file and also make centralized editions to the code. The scripts are downloaded and imported into this python notebook using the code in the cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIWIDctWtYnb"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "def import_github_script(URL: str, file_name: str) -> None:\n",
        "    r\"\"\"\n",
        "    Function retrieves Python scripts from github page and creates an importable file with extension ``.py``.\n",
        "\n",
        "    This function aims to allow the code modifications to be made at Github, maintaining cleaness of coding\n",
        "    and allowing modifications to be readily available in any copy of the notebook.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    URL : ``str``\n",
        "        URL address containing the file.\n",
        "    file_name : ``str``\n",
        "        Name to be given to the downloaded file.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ``None``\n",
        "    \"\"\"\n",
        "    path = file_name + '.py'\n",
        "    if (not os.path.isfile(path)):\n",
        "        raw_bytes = urllib.request.urlopen(URL).read()\n",
        "        raw_str = raw_bytes.decode(\"utf-8\")\n",
        "        mode = 'x'\n",
        "        text_file = open(path, mode)\n",
        "        text_file.write(raw_str)\n",
        "        text_file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2eUtbxVmOm4"
      },
      "outputs": [],
      "source": [
        "# DOWNLOADING SCRIPTS FROM GITHUB\n",
        "import_github_script(r'https://raw.githubusercontent.com/luiz-resende/ReinforcementLearning/main/A03_DQN/utils/dqn_memory_buffer.py',\n",
        "                     r'dqn_memory_buffer')\n",
        "import_github_script(r'https://raw.githubusercontent.com/luiz-resende/ReinforcementLearning/main/A03_DQN/models/dqn_models_torch.py',\n",
        "                     r'dqn_models_torch')\n",
        "import_github_script(r'https://raw.githubusercontent.com/luiz-resende/ReinforcementLearning/main/A03_DQN/utils/dqn_wrappers_env.py',\n",
        "                     r'dqn_wrappers_env')\n",
        "import_github_script(r'https://raw.githubusercontent.com/luiz-resende/ReinforcementLearning/main/A03_DQN/agent/dqn_agent_atari.py',\n",
        "                     r'dqn_agent_atari')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kyilXg4JGOu"
      },
      "source": [
        "## **Training Pipeline**\n",
        "\n",
        "The different experiments performed are shown and commented below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue3xD_8VwSQk"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from dqn_agent_atari import AgentDQN  # IMPORTING EXPERIMENT AGENT SCRIPT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "focUg0hdcC13"
      },
      "source": [
        "### 1 - Testing size of experience replay memory\n",
        "\n",
        "All experiments in this section used the hyper-parameters shown in the dictionaries below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW8dwU9NcSL4"
      },
      "outputs": [],
      "source": [
        "config_env = {'game_id': 'Pong-v4',\n",
        "              'is_minatar': False,\n",
        "              'render_mode': 'rgb_array',\n",
        "              'max_episode_steps': None,\n",
        "              'no_op_reset_env': True,\n",
        "              'no_op_max_env': 30,\n",
        "              'skip_frames_env': True,\n",
        "              'skip_frames_env_n': 4,\n",
        "              'wrap_env': True,\n",
        "              'clip_rewards': True,\n",
        "              'episodic_life': True,\n",
        "              'scale_frame': False,\n",
        "              'stack_frames': True,\n",
        "              'warp_frames': True,\n",
        "              'warp_frames_greyscale': True,\n",
        "              }\n",
        "\n",
        "config_model = {'in_channels': 4,\n",
        "                'out_channel': 32,\n",
        "                'shape_input': (84, 84),\n",
        "                'kernel': (8, 8),\n",
        "                'stride': (4, 4),\n",
        "                'padding': (0, 0),\n",
        "                'out_features_linear': 512,\n",
        "                'agent_architecture': 2,\n",
        "                'use_batch_norm': False,\n",
        "                'scale_batch_input': 255.0,\n",
        "                'device': 'gpu',\n",
        "                }\n",
        "\n",
        "config_optim = {'optimizer': 'RMSprop',\n",
        "                'loss_criterion': 'smooth_l1_loss',  # 'huber_loss'\n",
        "                'gamma_disc': 0.99,\n",
        "                'learn_rate': 0.00025,\n",
        "                'grad_momentum': 0.95,\n",
        "                'grad_momentum_square': 0.95,\n",
        "                'min_sqr_grad': 0.01,\n",
        "                'epsilon_max': 1.00,\n",
        "                'epsilon_min': 0.10,\n",
        "                'eps_decay_interval': 1000000,\n",
        "                'exponential_decay': False,\n",
        "                'target_network_update': 10000,\n",
        "                }\n",
        "\n",
        "config_training = {'seed': 895359,\n",
        "                   'use_wandb_logging': True,\n",
        "                   'experiment_project_name': 'RL_ProjectTest_-_DQN_Atari_Pong-v4'\n",
        "                   'train_in_episodes': False,\n",
        "                   'max_number_training_frames': 5000000,\n",
        "                   }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KXnU1MMcdVN"
      },
      "source": [
        "#### 1.1 - Experience replay memory capacity equal to $100$k samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXPzJJYOiT6e"
      },
      "outputs": [],
      "source": [
        "config_memory = {'memory_capacity': 100000,\n",
        "                 'sample_batch_size': 32,\n",
        "                 'initial_memory': 50000,\n",
        "                  }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_ReplayMemory_size=100k',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 4 frame and 100k memory capacity.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnQFmmMqiT6l",
        "outputId": "850f3db2-0bcb-4636-a111-c15191ee3a0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [7:23:53<00:00, 187.73 frames/s, AvgRewardEps=16.7, AvgSteps=1.98e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvRsyNtpiT6m",
        "outputId": "62076d5d-3dba-47c8-8d5d-2e57eb4d705e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.18 +/- 4.048\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8Z6jSQWdNiF"
      },
      "source": [
        "#### 1.2 - Experience replay memory capacity equal to $250$k samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlpnM_YQdNiQ"
      },
      "outputs": [],
      "source": [
        "config_memory = {'memory_capacity': 250000,\n",
        "                 'sample_batch_size': 32,\n",
        "                 'initial_memory': 50000,\n",
        "                  }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_ReplayMemory_size=250k',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 4 frame and 250k memory capacity.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdJzrMzUdNiR",
        "outputId": "77139d10-8fd8-444b-b332-05dcd8e015c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [7:23:28<00:00, 187.91 frames/s, AvgRewardEps=16, AvgSteps=1.98e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOpcm_CIeYc5",
        "outputId": "cc2a6bb1-ac35-48a5-f0f8-f5683d2a45fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.74 +/- 1.82\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_tNCS7uhBfx"
      },
      "source": [
        "#### 1.3 - Experience replay memory capacity equal to $500$k samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlYZGIQ7hBf6"
      },
      "outputs": [],
      "source": [
        "config_memory = {'memory_capacity': 500000,\n",
        "                 'sample_batch_size': 32,\n",
        "                 'initial_memory': 50000,\n",
        "                  }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_ReplayMemory_size=500k',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 4 frame and 500k memory capacity.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h8wEASkhBf6",
        "outputId": "1abdadae-2de8-4b2c-ba70-dd3308bcf937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [9:33:06<00:00, 145.40 frames/s, AvgRewardEps=16.2, AvgSteps=1983.33, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjarJ0_6hBf7",
        "outputId": "469f70f4-fbcf-43c4-dc52-2d3fc8b95602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 21.0 +/- 0.0\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qXlgGlchOp1"
      },
      "source": [
        "#### 1.4 - Experience replay memory capacity equal to $1$M samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLBFR5dYhOp1"
      },
      "outputs": [],
      "source": [
        "config_memory = {'memory_capacity': 1000000,\n",
        "                 'sample_batch_size': 32,\n",
        "                 'initial_memory': 50000,\n",
        "                  }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_ReplayMemory_size=1M',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 4 frame and 1M memory capacity.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kinFp2zhOp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccfdc4d1-d680-40ec-ff73-ad4f465d173e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [41:42:50<00:00, 33.30 frames/s, AvgRewardEps=15.3, AvgSteps=2.02e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gd4oUgzhOp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6820684f-fbc3-48ed-ca99-d0737c2c2e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.52 +/- 0.608\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTKueUg8lWOI"
      },
      "source": [
        "### 2 - Testing policy model update frequency\n",
        "\n",
        "All experiments in this section used the hyper-parameters shown in the dictionaries below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8yFLMiRlWOL"
      },
      "outputs": [],
      "source": [
        "config_env = {'game_id': 'Pong-v4',\n",
        "              'is_minatar': False,\n",
        "              'render_mode': 'rgb_array',\n",
        "              'max_episode_steps': None,\n",
        "              'no_op_reset_env': True,\n",
        "              'no_op_max_env': 30,\n",
        "              'skip_frames_env': True,\n",
        "              'skip_frames_env_n': 4,\n",
        "              'wrap_env': True,\n",
        "              'clip_rewards': True,\n",
        "              'episodic_life': True,\n",
        "              'scale_frame': False,\n",
        "              'stack_frames': True,\n",
        "              'warp_frames': True,\n",
        "              'warp_frames_greyscale': True,\n",
        "              }\n",
        "\n",
        "config_model = {'in_channels': 4,\n",
        "                'out_channel': 32,\n",
        "                'shape_input': (84, 84),\n",
        "                'kernel': (8, 8),\n",
        "                'stride': (4, 4),\n",
        "                'padding': (0, 0),\n",
        "                'out_features_linear': 512,\n",
        "                'agent_architecture': 2,\n",
        "                'use_batch_norm': False,\n",
        "                'scale_batch_input': 255.0,\n",
        "                'device': 'gpu',\n",
        "                }\n",
        "\n",
        "config_optim = {'optimizer': 'RMSprop',\n",
        "                'loss_criterion': 'smooth_l1_loss',  # 'huber_loss'\n",
        "                'gamma_disc': 0.99,\n",
        "                'learn_rate': 0.00025,\n",
        "                'grad_momentum': 0.95,\n",
        "                'grad_momentum_square': 0.95,\n",
        "                'min_sqr_grad': 0.01,\n",
        "                'epsilon_max': 1.00,\n",
        "                'epsilon_min': 0.10,\n",
        "                'eps_decay_interval': 1000000,\n",
        "                'exponential_decay': False,\n",
        "                'target_network_update': 10000,\n",
        "                }\n",
        "\n",
        "config_memory = {'memory_capacity': 500000,\n",
        "                 'sample_batch_size': 32,\n",
        "                 'initial_memory': 50000,\n",
        "                  }\n",
        "\n",
        "config_training = {'seed': 895359,\n",
        "                   'use_wandb_logging': True,\n",
        "                   'experiment_project_name': 'RL_ProjectTest_-_DQN_Atari_Pong-v4',\n",
        "                   'train_in_episodes': False,\n",
        "                   'max_number_training_frames': 5000000,\n",
        "                   }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCbZkygA5pFN"
      },
      "source": [
        "#### 2.1 - Update policy model after every $k=1$ steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oppiza4WDy_c"
      },
      "outputs": [],
      "source": [
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_UpdateFrequency_k=1',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 1 frame and 500k memory capacity.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2WlDBSYlWOM",
        "outputId": "2b95affa-671f-4986-f46a-a2c5c13944f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [32:12:39<00:00, 43.12 frames/s, AvgRewardEps=14.7, AvgSteps=1.97e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=1,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qo2WqLcrjP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3cab530-80e8-445b-f1f7-44569b6fa2eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.68 +/- 0.466\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txqfo-dflIzi"
      },
      "source": [
        "#### 2.2 - Update policy model after every $k=4$ steps (base-line)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbvuJb8YDvY8"
      },
      "outputs": [],
      "source": [
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_UpdateFrequency_k=4_(baseline)',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 4 frames and 500k memory capacity.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SOph0sTpbBY",
        "outputId": "f0a51737-5330-44eb-8b2a-04ea7d2a48d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [9:33:06<00:00, 145.40 frames/s, AvgRewardEps=16.2, AvgSteps=1983.33, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k30nB9pmlE5O",
        "outputId": "0158db8b-8474-4c6a-9e61-eb434ba10019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 21.0 +/- 0.0\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHTtVsAUHUgj"
      },
      "source": [
        "#### 2.3 - Update policy model after every $k=5$ steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WaNoCXzHUgp"
      },
      "outputs": [],
      "source": [
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_UpdateFrequency_k=5',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 5 frames and 500k memory capacity.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d36f19-5bdc-4fa0-eb48-6f766b553773",
        "id": "35WfsZlaHUgp"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [6:53:07<00:00, 201.71 frames/s, AvgRewardEps=16.1, AvgSteps=1.98e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=5,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54e481b-6568-47a5-a98a-b94dee122c9f",
        "id": "6xwJb0juHUgp"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.96 +/- 0.28\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()  # Evaluation time 3.9 min\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd0MUPhSl3cQ"
      },
      "source": [
        "#### 2.4 - Update policy model after every $k=10$ steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB3zJv3GCXJo"
      },
      "outputs": [],
      "source": [
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_UpdateFrequency_k=10',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 10 frames and 500k memory capacity.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmMMzKXKl3cT",
        "outputId": "a96cb545-a594-4578-c334-60b220bf02c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [5:37:36<00:00, 246.83 frames/s, AvgRewardEps=16.3, AvgSteps=2.04e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=10,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOiHj-0glJNJ",
        "outputId": "4d80a3ea-0ea8-4015-a570-81b573e8524e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.82 +/- 0.384\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Nyj06hqhsE"
      },
      "source": [
        "### 3 - Testing different network architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVq7v3ufleUZ"
      },
      "outputs": [],
      "source": [
        "config_env = {'game_id': 'Pong-v4',\n",
        "              'is_minatar': False,\n",
        "              'render_mode': 'rgb_array',\n",
        "              'max_episode_steps': None,\n",
        "              'no_op_reset_env': True,\n",
        "              'no_op_max_env': 30,\n",
        "              'skip_frames_env': True,\n",
        "              'skip_frames_env_n': 4,\n",
        "              'wrap_env': True,\n",
        "              'clip_rewards': True,\n",
        "              'episodic_life': True,\n",
        "              'scale_frame': False,\n",
        "              'stack_frames': True,\n",
        "              'warp_frames': True,\n",
        "              'warp_frames_greyscale': True,\n",
        "              }\n",
        "\n",
        "config_optim = {'optimizer': 'RMSprop',\n",
        "                'loss_criterion': 'smooth_l1_loss',  # 'huber_loss'\n",
        "                'gamma_disc': 0.99,\n",
        "                'learn_rate': 0.00025,\n",
        "                'grad_momentum': 0.95,\n",
        "                'grad_momentum_square': 0.95,\n",
        "                'min_sqr_grad': 0.01,\n",
        "                'epsilon_max': 1.00,\n",
        "                'epsilon_min': 0.10,\n",
        "                'eps_decay_interval': 1000000,\n",
        "                'exponential_decay': False,\n",
        "                'target_network_update': 10000,\n",
        "                }\n",
        "\n",
        "config_memory = {'memory_capacity': 500000,\n",
        "                 'sample_batch_size': 32,\n",
        "                 'initial_memory': 50000,\n",
        "                 }\n",
        "\n",
        "config_training = {'seed': 895359,\n",
        "                   'use_wandb_logging': True,\n",
        "                   'experiment_project_name': 'RL_ProjectTest_-_DQN_Atari_Pong-v4',\n",
        "                   'train_in_episodes': False,\n",
        "                   'max_number_training_frames': 5000000,\n",
        "                   }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsK5MUlFtewv"
      },
      "source": [
        "#### 3.1 Using network architecture from Mnih et al. (2015) with only 1 convolutional layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix-zq7cbaliY"
      },
      "outputs": [],
      "source": [
        "config_model = {'in_channels': 4,\n",
        "                'out_channel': 32,\n",
        "                'shape_input': (84, 84),\n",
        "                'kernel': (8, 8),\n",
        "                'stride': (4, 4),\n",
        "                'padding': (0, 0),\n",
        "                'out_features_linear': 512,\n",
        "                'agent_architecture': 3,\n",
        "                'use_batch_norm': False,\n",
        "                'scale_batch_input': 255.0,\n",
        "                'device': 'gpu',\n",
        "                }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_Architecture_3_minimal',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 3.' +\n",
        "                                        ' Using model update frequency of every 4 frames, 500k memory capacity' +\n",
        "                                        ' and a network architecture with a single conv. layer.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y25KGl1caliZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40ca579-7738-42d7-99bf-ac36a15f24e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [8:37:57<00:00, 160.89 frames/s, AvgRewardEps=-13, AvgSteps=1.43e+3, RewardMax=-2]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6WRuAvklUSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36ff4fa-c7dd-4bc0-c57b-6c4d7710498d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : -3.86 +/- 3.633\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPww-0zIYszH"
      },
      "source": [
        "#### 3.2 Using network architecture from Mnih et al. (2013) with parameters from  Mnih et al. (2015)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6eqjlzFZmva"
      },
      "outputs": [],
      "source": [
        "config_model = {'in_channels': 4,\n",
        "                'out_channel': 32,\n",
        "                'shape_input': (84, 84),\n",
        "                'kernel': (8, 8),\n",
        "                'stride': (4, 4),\n",
        "                'padding': (0, 0),\n",
        "                'out_features_linear': 512,\n",
        "                'agent_architecture': 1,\n",
        "                'use_batch_norm': False,\n",
        "                'scale_batch_input': 255.0,\n",
        "                'device': 'gpu',\n",
        "                }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_Architecture_1_2013',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 1.' +\n",
        "                                        ' Using model update frequency of every 4 frames and 500k memory capacity' +\n",
        "                                        ' and a network architecture with two conv. layers (Mnih et al., 2013).')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihpfplyNZmvi",
        "outputId": "77b37189-3ed7-4534-9fe1-87babf9dab43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [7:16:08<00:00, 191.07 frames/s, AvgRewardEps=16.8, AvgSteps=2.08e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNYLVkVllQBy",
        "outputId": "2c765935-8e8b-4cad-f6bf-24617ec79f7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.44 +/- 0.92\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rwZ31Uqa2hJ"
      },
      "source": [
        "#### 3.3 Using network architecture from Mnih et al. (2015) with an additional convolutional layer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_model = {'in_channels': 4,\n",
        "                'out_channel': 32,\n",
        "                'shape_input': (84, 84),\n",
        "                'kernel': (8, 8),\n",
        "                'stride': (4, 4),\n",
        "                'padding': (0, 0),\n",
        "                'out_features_linear': 512,\n",
        "                'agent_architecture': 4,\n",
        "                'use_batch_norm': False,\n",
        "                'scale_batch_input': 255.0,\n",
        "                'device': 'gpu',\n",
        "                }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_Architecture_4_larger',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 4.' +\n",
        "                                        ' Using model update frequency of every 4 frames and 500k memory capacity' +\n",
        "                                        ' and a network architecture with four conv. layers.')\n",
        "                  )\n"
      ],
      "metadata": {
        "id": "2ouB3Jduk_L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350efd8d-78e8-443f-8d2c-db61972dea5c",
        "id": "wKuy0wUuk_MA"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [8:14:02<00:00, 168.68 frames/s, AvgRewardEps=15.3, AvgSteps=1.95e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.evaluate_agent()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6952eb-ed69-4909-cc25-64cdf5761d88",
        "id": "EiiFbsNVk_MA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.3 +/- 2.934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rotMVZexPYIV"
      },
      "source": [
        "#### 3.4 Using network architecture from Mnih et al. (2013) with parameters from  Mnih et al. (2015) and applying batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YImBisBPYIc"
      },
      "outputs": [],
      "source": [
        "config_model = {'in_channels': 4,\n",
        "                'out_channel': 32,\n",
        "                'shape_input': (84, 84),\n",
        "                'kernel': (8, 8),\n",
        "                'stride': (4, 4),\n",
        "                'padding': (0, 0),\n",
        "                'out_features_linear': 512,\n",
        "                'agent_architecture': 1,\n",
        "                'use_batch_norm': True,\n",
        "                'scale_batch_input': 255.0,\n",
        "                'device': 'gpu',\n",
        "                }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_Architecture_1_2013_batch_norm',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 1.' +\n",
        "                                        ' Using model update frequency of every 4 frames and 500k memory capacity' +\n",
        "                                        ' and a network architecture with two conv. layers (Mnih et al., 2013) and batch norm.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZT3y2h8PYIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e948999f-8878-4891-b020-1f225a8b2450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [7:50:12<00:00, 177.23 frames/s, AvgRewardEps=17.7, AvgSteps=1.96e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRlC_FNEPYIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b033aaf-5119-4558-abcf-24d42e2e2ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 18.6 +/- 3.194\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94Bhu6yBPrYZ"
      },
      "source": [
        "#### 3.5 Using network architecture from Mnih et al. (2015) and applying batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_model = {'in_channels': 4,\n",
        "                'out_channel': 32,\n",
        "                'shape_input': (84, 84),\n",
        "                'kernel': (8, 8),\n",
        "                'stride': (4, 4),\n",
        "                'padding': (0, 0),\n",
        "                'out_features_linear': 512,\n",
        "                'agent_architecture': 2,\n",
        "                'use_batch_norm': True,\n",
        "                'scale_batch_input': 255.0,\n",
        "                'device': 'gpu',\n",
        "                }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_Architecture_2_2015_batch_norm_2',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 4 frames and 500k memory capacity' +\n",
        "                                        ' and a network architecture with three conv. layers (Mnih et al., 2015) and batch norm.')\n",
        "                  )\n"
      ],
      "metadata": {
        "id": "q3ENmzB8PrYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a04da63-5297-4d86-f572-9c59cef18419",
        "id": "KyI9STrtf2Jk"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [10:54:36<00:00, 127.30 frames/s, AvgRewardEps=17.1, AvgSteps=1.89e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.evaluate_agent()  # Evaluation time is approximately 5.7 min\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBm4UzPi5X4F",
        "outputId": "05f54fd5-2911-45ea-c276-cc5338961f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.8 +/- 1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwmkotA3PYIc"
      },
      "source": [
        "#### 3.6 Using network architecture from Mnih et al. (2015) with an additional convolutional layer and applying batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_model = {'in_channels': 4,\n",
        "                'out_channel': 32,\n",
        "                'shape_input': (84, 84),\n",
        "                'kernel': (8, 8),\n",
        "                'stride': (4, 4),\n",
        "                'padding': (0, 0),\n",
        "                'out_features_linear': 512,\n",
        "                'agent_architecture': 4,\n",
        "                'use_batch_norm': True,\n",
        "                'scale_batch_input': 255.0,\n",
        "                'device': 'gpu',\n",
        "                }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_Architecture_4_larger_batch_norm',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 4.' +\n",
        "                                        ' Using model update frequency of every 4 frames and 500k memory capacity' +\n",
        "                                        ' and a network architecture with four conv. layers and batch norm.')\n",
        "                  )\n"
      ],
      "metadata": {
        "id": "jh8BdSu3PYId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJwAhkXBZGOW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68da10d-f2a8-4241-ccb3-6271b61ad90d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Training AgentDQN] :  82%|████████▏ | 4078304/5000000 [10:56:29<3:23:00, 75.67 frames/s, AvgRewardEps=16.6, AvgSteps=1.93e+3, RewardMax=21] "
          ]
        }
      ],
      "source": [
        " scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.evaluate_agent()\n"
      ],
      "metadata": {
        "id": "ugRM6FgnPYId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCyikneznJAr"
      },
      "source": [
        "#### 3.7 Using network architecture from Mnih et al. (2015) with only 1 convolutional layer and batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iorKz9VMnJAs"
      },
      "outputs": [],
      "source": [
        "config_model = {'in_channels': 4,\n",
        "                'out_channel': 32,\n",
        "                'shape_input': (84, 84),\n",
        "                'kernel': (8, 8),\n",
        "                'stride': (4, 4),\n",
        "                'padding': (0, 0),\n",
        "                'out_features_linear': 512,\n",
        "                'agent_architecture': 3,\n",
        "                'use_batch_norm': True,\n",
        "                'scale_batch_input': 255.0,\n",
        "                'device': 'gpu',\n",
        "                }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_Architecture_3_minimal_batch_norm',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 3.' +\n",
        "                                        ' Using model update frequency of every 4 frames, 500k memory capacity' +\n",
        "                                        ' and a network architecture with a single conv. layer and batch norm.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DazC2uPMnJAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b83650-31f3-4502-9b76-a3d6f084b3d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [7:30:23<00:00, 185.02 frames/s, AvgRewardEps=17.3, AvgSteps=1.93e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuCKdIJznJAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653ba205-2c91-470a-af9c-49303731b9da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.9 +/- 0.7\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()  # 4 min to evaluate agent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpmCumY3MkjN"
      },
      "source": [
        "### 4 - Testing different mini-batch sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQrv8eGXMkjT"
      },
      "outputs": [],
      "source": [
        "config_env = {'game_id': 'Pong-v4',\n",
        "              'is_minatar': False,\n",
        "              'render_mode': 'rgb_array',\n",
        "              'max_episode_steps': None,\n",
        "              'no_op_reset_env': True,\n",
        "              'no_op_max_env': 30,\n",
        "              'skip_frames_env': True,\n",
        "              'skip_frames_env_n': 4,\n",
        "              'wrap_env': True,\n",
        "              'clip_rewards': True,\n",
        "              'episodic_life': True,\n",
        "              'scale_frame': False,\n",
        "              'stack_frames': True,\n",
        "              'warp_frames': True,\n",
        "              'warp_frames_greyscale': True,\n",
        "              }\n",
        "\n",
        "config_optim = {'optimizer': 'RMSprop',\n",
        "                'loss_criterion': 'smooth_l1_loss',  # 'huber_loss'\n",
        "                'gamma_disc': 0.99,\n",
        "                'learn_rate': 0.00025,\n",
        "                'grad_momentum': 0.95,\n",
        "                'grad_momentum_square': 0.95,\n",
        "                'min_sqr_grad': 0.01,\n",
        "                'epsilon_max': 1.00,\n",
        "                'epsilon_min': 0.10,\n",
        "                'eps_decay_interval': 1000000,\n",
        "                'exponential_decay': False,\n",
        "                'target_network_update': 10000,\n",
        "                }\n",
        "\n",
        "config_model = {'in_channels': 4,\n",
        "                'out_channel': 32,\n",
        "                'shape_input': (84, 84),\n",
        "                'kernel': (8, 8),\n",
        "                'stride': (4, 4),\n",
        "                'padding': (0, 0),\n",
        "                'out_features_linear': 512,\n",
        "                'agent_architecture': 2,\n",
        "                'use_batch_norm': False,\n",
        "                'scale_batch_input': 255.0,\n",
        "                'device': 'gpu',\n",
        "                }\n",
        "\n",
        "config_training = {'seed': 895359,\n",
        "                   'use_wandb_logging': True,\n",
        "                   'experiment_project_name': 'RL_ProjectTest_-_DQN_Atari_Pong-v4',\n",
        "                   'train_in_episodes': False,\n",
        "                   'max_number_training_frames': 5000000,\n",
        "                   }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaP0np7pMkjT"
      },
      "source": [
        "#### 4.1 Using mini-batches of 16 samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPfIJDqjMkjT"
      },
      "outputs": [],
      "source": [
        "config_memory = {'memory_capacity': 500000,\n",
        "                 'sample_batch_size': 16,\n",
        "                 'initial_memory': 50000,\n",
        "                 }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_MiniBatchSize_b=16',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 4 frames, 500k memory capacity' +\n",
        "                                        ' and a mini-batch of 16 samples.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1752ea-4f9d-423a-b319-200bcdfe363d",
        "id": "v-00vuueMkjT"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [6:36:45<00:00, 210.04 frames/s, AvgRewardEps=10.8, AvgSteps=2.11e+3, RewardMax=20]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7zcAnJnMkjU",
        "outputId": "8b3c7c91-c50e-4484-b2ea-91a27eebee80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 17.64 +/- 3.497\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsV7KH3LNWyG"
      },
      "source": [
        "#### 4.2 Using mini-batches of 64 samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct26QG9zNWyL"
      },
      "outputs": [],
      "source": [
        "config_memory = {'memory_capacity': 500000,\n",
        "                 'sample_batch_size': 64,\n",
        "                 'initial_memory': 50000,\n",
        "                 }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_MiniBatchSize_b=64',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 4 frames, 500k memory capacity' +\n",
        "                                        ' and a mini-batch of 64 samples.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e13425e-f4be-4819-88df-654668f592e2",
        "id": "8NugQrnZdfmc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [9:19:07<00:00, 149.04 frames/s, AvgRewardEps=17.6, AvgSteps=1.98e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2828076-31f1-46fc-9f8b-7f99a2d0701a",
        "id": "SHsIZsJ5gMd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.28 +/- 0.801\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTEaozhganDJ"
      },
      "source": [
        "#### 4.3 Using mini-batches of 128 samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opDEWZQeanDJ"
      },
      "outputs": [],
      "source": [
        "config_memory = {'memory_capacity': 500000,\n",
        "                 'sample_batch_size': 128,\n",
        "                 'initial_memory': 50000,\n",
        "                 }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_MiniBatchSize_b=128',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 4 frames, 500k memory capacity' +\n",
        "                                        ' and a mini-batch of 128 samples.')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zvspujranDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043a461c-6ab3-4735-8a76-cd84b13a499a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [23:42:32<00:00, 58.58 frames/s, AvgRewardEps=16.8, AvgSteps=1.99e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52PcvEWKanDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f4b940-e37d-4695-f39a-7b744ac6840d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.68 +/- 0.786\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTDmZnZvGkRg"
      },
      "source": [
        "#### 4.4 Using resizeable mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNFf6xQyGkRg"
      },
      "outputs": [],
      "source": [
        "config_memory = {'memory_capacity': 500000,\n",
        "                 'sample_batch_size': [16, 32, 64, 128],\n",
        "                 'initial_memory': 50000,\n",
        "                 }\n",
        "\n",
        "agent = AgentDQN(configuration_environment=config_env,\n",
        "                  configuration_dqn_models=config_model,\n",
        "                  configuration_optimization=config_optim,\n",
        "                  configuration_memory_replay=config_memory,\n",
        "                  seed=config_training['seed'],\n",
        "                  use_wandb_logging=config_training['use_wandb_logging'],\n",
        "                  experiment_project_name=config_training['experiment_project_name'],\n",
        "                  experiment_run_name='Test_MiniBatchSize_b=[16, 32, 64, 128]',\n",
        "                  experiment_run_notes=('Training run with a maximum of 5M frames and architecture 2.' +\n",
        "                                        ' Using model update frequency of every 4 frames, 500k memory capacity' +\n",
        "                                        ' and a resizable mini-batch in [16, 32, 64, 128].')\n",
        "                  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5jaCb5BGkRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6dd7670-4576-4cd3-bcea-b282237c5176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Training AgentDQN] : 100%|██████████| 5000000/5000000 [12:35:03<00:00, 110.37 frames/s, AvgRewardEps=17.2, AvgSteps=2.03e+3, RewardMax=21]\n"
          ]
        }
      ],
      "source": [
        "scores = agent.train_agent(train_in_episodes=config_training['train_in_episodes'],\n",
        "                           max_number_training_frames=config_training['max_number_training_frames'],\n",
        "                           update_frequency_model=4,\n",
        "                           render=False,\n",
        "                           render_mode='rgb_array',\n",
        "                           save_tensors_in_memory_buffer=True,\n",
        "                           load_agent_state=False,\n",
        "                           load_agent_info=None,\n",
        "                           save_iterruption=True\n",
        "                           )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWO79EipGkRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32a8c2a-0cba-44a2-9dec-c3bb773adc52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Final average score] : 20.64 +/- 2.52\n"
          ]
        }
      ],
      "source": [
        "agent.evaluate_agent()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.save_agent_state(base_file_name='', postfix='batch_size_resizeable')\n"
      ],
      "metadata": {
        "id": "DpT-6TEZGkRh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "H7fQzHLIs9gW",
        "L-dryvkoNa30",
        "jx5DgyW-NlZH",
        "uz5pXpPXORIC",
        "_Fe2XHN4QTDh",
        "focUg0hdcC13",
        "6KXnU1MMcdVN",
        "F8Z6jSQWdNiF",
        "Q_tNCS7uhBfx",
        "7qXlgGlchOp1",
        "PTKueUg8lWOI",
        "VCbZkygA5pFN",
        "Txqfo-dflIzi",
        "zHTtVsAUHUgj",
        "yd0MUPhSl3cQ",
        "c3Nyj06hqhsE",
        "SsK5MUlFtewv",
        "EPww-0zIYszH",
        "0rwZ31Uqa2hJ",
        "rotMVZexPYIV",
        "94Bhu6yBPrYZ",
        "XwmkotA3PYIc",
        "XCyikneznJAr",
        "NpmCumY3MkjN",
        "DaP0np7pMkjT",
        "QsV7KH3LNWyG",
        "pTEaozhganDJ",
        "OTDmZnZvGkRg"
      ],
      "machine_shape": "hm",
      "name": "INF8953DE_-_Atari_DQN_Training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
